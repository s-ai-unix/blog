# TIC 审核员检查清单

## 审核员角色定位

作为 TIC 机构（DEKRA、TÜV SÜD、SGS 等）的审核员，你的核心任务是：
- **验证合规性**：确认客户系统符合法规和标准要求
- **评估有效性**：评估客户的控制措施是否有效
- **识别差距**：发现不符合项并提出改进建议
- **颁发证书**：根据审核结果颁发认证证书

## 审核方法论

### 审核类型

#### 文档审核 (Document Review)
**目标**：评估技术文档的完整性和符合性
**方法**：
- 检查文档清单是否完整
- 验证文档内容是否符合要求
- 评估文档的一致性

#### 现场审核 (On-site Audit)
**目标**：验证实施的有效性
**方法**：
- 面谈（interview）
- 现场观察
- 记录抽样检查
- 演示（witness）

#### 技术审核 (Technical Assessment)
**目标**：评估技术实现
**方法**：
- 代码审查
- 测试结果验证
- 实验室测试（如需要）

## EU AI Act 高风险 AI 系统审核清单

### A. 风险管理系统 (Article 9)

#### 检查项
- [ ] 风险管理流程是否已建立？
- [ ] 全生命周期风险是否已识别？
- [ ] 风险评估方法是否适当？
- [ ] 缓解措施是否有效？

#### 审核证据
- 风险管理流程文档
- 风险登记册
- 风险评估报告
- 缓解措施验证记录

#### 审核提示
"请展示你们的 AI 风险评估方法学，以及如何与 ISO 26262 的 HARA 和 ISO 21448 的 SOTIF 分析协调。"

### B. 数据与数据治理 (Article 10)

#### 检查项
- [ ] 数据集是否有完整文档？
- [ ] 数据质量评估是否完成？
- [ ] 偏见检测是否进行？
- [ ] 数据来源合法性是否确认？

#### 审核证据
- 数据集文档（Data Sheet）
- 数据质量评估报告
- 偏见分析报告
- 数据处理协议（GDPR 合规）

#### 审核提示
"请提供训练数据的来源证明，以及如何确保数据代表性和避免偏见的措施。"

### C. 技术文档 (Article 11)

#### 检查项
- [ ] 系统描述是否完整？
- [ ] 架构和算法是否清楚？
- [ ] 性能指标是否定义？
- [ ] 测试结果是否充分？

#### 审核证据
- 技术文档（主文档）
- 系统架构图
- 算法描述
- 测试报告

#### 审核提示
"请展示系统架构图，以及 AI 组件如何与车辆其他系统集成的说明。"

### D. 记录保存 (Article 12)

#### 检查项
- [ ] 日志记录机制是否实施？
- [ ] 日志内容是否充分？
- [ ] 日志存储是否安全？
- [ ] 保留期限是否合规？

#### 审核证据
- 日志记录策略
- 日志样本
- 存储安全措施
- 保留政策

#### 审核提示
"请展示最近一周的系统运行日志，以及如何通过日志追溯 AI 决策过程。"

### E. 透明度与信息提供 (Article 13)

#### 检查项
- [ ] 用户信息是否充分？
- [ ] 系统限制是否说明？
- [ ] 风险是否告知？

#### 审核证据
- 用户信息文档
- 系统使用说明
- 风险提示

#### 审核提示
"请展示提供给终端用户的信息材料，以及如何说明 AI 系统的能力和限制。"

### F. 人工监督 (Article 14)

#### 检查项
- [ ] 监督机制是否设计？
- [ ] 干预点是否定义？
- [ ] 人员是否培训？

#### 审核证据
- 人工监督策略
- 干预点和条件
- 培训记录

#### 审核提示
"请说明在什么情况下需要人工干预，以及干预的具体流程和责任人。"

### G. 准确性、鲁棒性和网络安全 (Article 15)

#### 检查项
- [ ] 准确性指标是否定义？
- [ ] 鲁棒性测试是否完成？
- [ ] 网络安全措施是否实施？

#### 审核证据
- 准确性测试报告
- 鲁棒性验证（对抗样本、OOD）
- 网络安全评估（ISO 21434）
- 异常行为检测

#### 审核提示
"请展示对抗样本测试的结果，以及如何确保系统在分布外数据下的鲁棒性。"

## ISO 42001 AIMS 审核清单

### 条款 4: 组织环境
- [ ] 组织背景是否理解？
- [ ] 相关方需求是否识别？
- [ ] AI 系统范围是否确定？
- [ ] AIMS 范围是否明确？

### 条款 5: 领导力
- [ ] AI 政策是否发布？
- [ ] 角色和职责是否分配？
- [ ] 治理结构是否建立？

### 条款 6: 规划
- [ ] 风险和机遇是否识别？
- [ ] AI 目标是否设定？
- [ ] 变更规划是否考虑？

### 条款 7: 支持
- [ ] 资源是否充分？
- [ ] 能力是否具备？
- [ ] 意识是否建立？
- [ ] 沟通是否有效？
- [ ] 文件化信息是否控制？

### 条款 8: 运行
- [ ] 运行规划是否适当？
- [ ] AI 系统评估是否进行？

### 条款 9: 绩效评价
- [ ] 监视和测量是否实施？
- [ ] 内部审核是否按计划进行？
- [ ] 管理评审是否定期进行？

### 条款 10: 改进
- [ ] 不合格是否处理？
- [ ] 纠正措施是否有效？
- [ ] 持续改进是否体现？

## 汽车特定审核要点

### 与 ISO 26262 集成
- [ ] HARA 分析是否考虑 AI 特性？
- [ ] ASIL 等级对 AI 组件的要求？
- [ ] 故障检测机制是否覆盖 AI？
- [ ] 安全目标是否与 AI 性能指标对齐？

### 与 ISO 21448 (SOTIF) 集成
- [ ] SOTIF 分析是否覆盖 AI 场景？
- [ ] 已知安全场景是否验证？
- [ ] 未知安全场景是否识别？
- [ ] 缓解措施是否有效？

### 与 ISO 21434 网络安全集成
- [ ] TARA 是否覆盖 AI 特定威胁？
- [ ] AI 对抗攻击是否考虑？
- [ ] 数据投毒防护是否实施？
- [ ] 模型窃取防护是否考虑？

## 审核员常见问题示例

### 开放式问题（用于评估理解）
- "请解释你们的 AI 系统如何满足 EU AI Act Article 9 的风险管理要求。"
- "你们如何确保训练数据的质量和代表性？"
- "请说明在什么情况下需要人工干预，以及如何确保干预的及时性。"

### 证据请求（用于验证）
- "请提供过去三个月的数据质量评估报告。"
- "请展示最近的对抗样本测试结果。"
- "请提供 AI 模型的版本更新记录和重新验证报告。"

### 场景问题（用于评估实施）
- "如果发现 AI 系统在特定场景下表现不佳，你们的处理流程是什么？"
- "当训练数据发现隐私问题时，你们如何处理？"
- "如果 AI 模型更新后性能下降，你们的回滚流程是什么？"

## 不符合项分类

### 严重不符合项 (Major Nonconformity)
- 系统性缺失（如完全缺少风险管理流程）
- 高风险未控制（如数据来源不合法）
- 欺骗行为（如伪造测试数据）

### 轻微不符合项 (Minor Nonconformity)
- 个别文件缺失
- 局部流程不符合
- 文档不完整

### 改进机会 (Observation)
- 优化建议
- 最佳实践分享

## 审核报告模板

### 执行摘要
- 审核范围和目标
- 总体评估
- 主要发现
- 认证建议

### 详细发现
- 符合项
- 不符合项（严重/轻微）
- 改进机会

### 验证要求
- 不符合项纠正期限
- 证据要求
- 后续审核计划

## 审核员专业提示

### 审核技巧
1. **遵循证据链**：从政策到流程到记录
2. **关注接口**：不同标准和法规的交叉点
3. **验证有效性**：不仅是文档，更要看实际效果
4. **保持独立性**：客观公正，不带偏见

### 常见风险点
1. **数据合规**：GDPR、数据来源合法性
2. **测试充分性**：边界案例、对抗样本
3. **变更管理**：AI 模型更新的控制
4. **供应链**：供应商 AI 系统的合规性

### 最佳实践
- 基于风险的审核（高风险重点审核）
- 流程导向的审核（关注系统性）
- 持续改进思维（帮助客户提升）
